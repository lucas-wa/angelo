{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esse arquivo foi feito para ser executado no Google Colab\n",
    "!git clone https://github.com/lucas-wa/angelo.git\n",
    "!mv angelo/* .\n",
    "!rm -rf ./angelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install realesrgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install basicsr facexlib gfpgan opencv-python Pillow torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando dependÃªncias do ngrock\n",
    "!pip install flask-ngrok flask-cors\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngrok config add-authtoken YOUR_NGROK_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando stable diffusion\n",
    "!pip install diffusers transformers accelerate scipy safetensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "editor_pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "editor_pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import queue\n",
    "import threading\n",
    "from PIL import Image\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "from pyngrok import ngrok\n",
    "from flask_cors import CORS\n",
    "\n",
    "from inference_realesrgan import upscale_image\n",
    "\n",
    "# from classes.stable_diffusion import StableDiffusion\n",
    "# from classes.stable_painting import StablePainting\n",
    "from classes.esrgan import ESRGAN\n",
    "\n",
    "request_queue = queue.Queue()\n",
    "\n",
    "app = Flask(__name__)\n",
    "cors = CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "port = 5000\n",
    "\n",
    "\n",
    "\n",
    "public_url = ngrok.connect(port).public_url\n",
    "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
    "\n",
    "app.config[\"BASE_URL\"] = public_url\n",
    "app.config['UPLOAD_FOLDER'] = 'images/'\n",
    "\n",
    "\n",
    "def process_requests():\n",
    "    while True:\n",
    "      try:\n",
    "        req, service, response_queue, status_code = request_queue.get()\n",
    "\n",
    "        if service == \"generator\":\n",
    "\n",
    "          prompt = req[\"prompt\"]\n",
    "          stable_diffusion = StableDiffusion(\"\", prompt)\n",
    "          response = stable_diffusion.gerar_imagem()\n",
    "          status_code = 200\n",
    "          response_queue.put((response, status_code))\n",
    "\n",
    "        elif service == \"upscale\":\n",
    "\n",
    "          # Process the request here and generate the response\n",
    "          file = req['file']\n",
    "          file = base64.b64decode(file)\n",
    "          filename = \"image.png\"\n",
    "\n",
    "          esrgan = ESRGAN(\"\")\n",
    "\n",
    "          image = esrgan.upscale_imagem(file, \"image.png\")\n",
    "          image = Image.fromarray(image)\n",
    "          buffered = io.BytesIO()\n",
    "          image.save(buffered, format=\"PNG\")\n",
    "          img_str = base64.b64encode(buffered.getvalue())\n",
    "          response = \"data:image/png;base64,\" + str(img_str)[2:-1]\n",
    "          response_queue.put((response, status_code))\n",
    "\n",
    "\n",
    "        elif service == \"editor\":\n",
    "\n",
    "          prompt = req[\"prompt\"]\n",
    "\n",
    "          stable_painting = StablePainting(\"\", prompt)\n",
    "\n",
    "          response = stable_painting.editar_imagem(req)\n",
    "\n",
    "          response_queue.put((response, status_code))\n",
    "\n",
    "\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        response = \"Internal server error. Image couldn't be generated\"\n",
    "        status_code = 500\n",
    "        response_queue.put((response, status_code))\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods = ['GET', 'POST'])\n",
    "def index():\n",
    "\n",
    "  return render_template(\"index.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/generator\", methods = ['POST'])\n",
    "def image_generator():\n",
    "  try:\n",
    "    status_code = 200\n",
    "    req = request.get_json()\n",
    "    prompt = req[\"prompt\"]\n",
    "    service = 'generator'\n",
    "    if (\"prompt\" not in req) or (prompt == ''):\n",
    "          return jsonify({\"error\": \"Prompt is missing\"}), 400\n",
    "\n",
    "    response_queue = queue.Queue()\n",
    "    request_queue.put((req, service, response_queue, status_code))\n",
    "    response, status_code = response_queue.get()\n",
    "    if(status_code == 500):\n",
    "        return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "    return jsonify({\"image_raw\": response})\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return jsonify({\"error\": e})\n",
    "\n",
    "\n",
    "@app.route(\"/upscale\", methods = ['POST'])\n",
    "def upsacle_image():\n",
    "  try:\n",
    "    req = request.get_json()\n",
    "\n",
    "    if 'file' not in req:\n",
    "      return jsonify({\"error\": \"No file\"}), 400\n",
    "\n",
    "    service = 'upscale'\n",
    "\n",
    "\n",
    "    status_code = 200\n",
    "    response_queue = queue.Queue()\n",
    "    request_queue.put((req, service, response_queue, status_code))\n",
    "    reponse, status_code = response_queue.get()\n",
    "    return jsonify({\"image_raw\": reponse}), 200\n",
    "\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/editor\", methods = ['POST'])\n",
    "def edit_image():\n",
    "  try:\n",
    "    req = request.get_json()\n",
    "\n",
    "    if 'file' not in req:\n",
    "      return jsonify({\"error\": \"No file\"}), 400\n",
    "\n",
    "    if 'mask' not in req:\n",
    "      return jsonify({\"error\": \"No mask\"}), 400\n",
    "\n",
    "    prompt = req[\"prompt\"]\n",
    "\n",
    "    if (\"prompt\" not in req) or (prompt == ''):\n",
    "      return jsonify({\"error\": \"Prompt or service is missing\"}), 400\n",
    "\n",
    "    service = 'editor'\n",
    "\n",
    "\n",
    "    status_code = 200\n",
    "    response_queue = queue.Queue()\n",
    "    request_queue.put((req, service, response_queue, status_code))\n",
    "    reponse, status_code = response_queue.get()\n",
    "    return jsonify({\"image_raw\": reponse}), 200\n",
    "\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "tr_stable = threading.Thread(target=process_requests)\n",
    "tr_stable.start()\n",
    "\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
